{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7d76bc1",
   "metadata": {},
   "source": [
    "### Jupyter Notebook 단축키\n",
    "- ctrl+enter: 셀 실행\n",
    "- shift+enter: 셀 실행 및 다음 셀 이동\n",
    "- alt+enter: 셀 실행, 다음 셀 이동, 새로운 셀 생성\n",
    "- a: 상단에 새로운 셀 만들기\n",
    "- b: 하단에 새로운 셀 만들기\n",
    "- dd: 셀 삭제(x: 셀 삭제)\n",
    "- esc: 셀 나가기\n",
    "- m: 마크다운 셀로 바꾸기\n",
    "- y: 마크다운 셀을 다시 Code로 바꾸기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a423db5",
   "metadata": {},
   "source": [
    "# 08장_사전 훈련된 모델 다루기\n",
    "\n",
    "* 개방적인 환경에서 빠르게 학습하기 위함\n",
    "* 전이 학습 (transfer learning), 신경 스타일 전이 (neural sytle transfer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b5a723",
   "metadata": {},
   "source": [
    "### 8.1 텐서플로 허브\n",
    "* TensorFlow Hub는 재사용 가능한 모델을 쉽게 이용할 수 있는 라이브러리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9ac6a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b966f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-hub\n",
      "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\seunghwan\\.conda\\envs\\nnew\\lib\\site-packages (from tensorflow-hub) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\seunghwan\\.conda\\envs\\nnew\\lib\\site-packages (from tensorflow-hub) (3.19.0)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.12.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5646bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 1001)              3540265   \n",
      "=================================================================\n",
      "Total params: 3,540,265\n",
      "Trainable params: 0\n",
      "Non-trainable params: 3,540,265\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로 허브에서 사전 훈련된 MobileNet 모델 불러오기\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "mobile_net_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2\"\n",
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(handle=mobile_net_url, input_shape=(224, 224, 3), trainable=False)\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "# MobileNet은 계산 부담이 큰 conv. 신경망을 연산 성능이 제한된 모바일 환경에서도 작동 가능하도록 네트워크 구조를 경량화 한 것\n",
    "# hub.KerasLayer()를 통해 tf.keras에서 사용 가능한 레이어로 변환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3abc2db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\content\\sample_data\\datasets\\imagenetv2-topimages\n"
     ]
    }
   ],
   "source": [
    "# ImageNetV2-TopImages 불러오기\n",
    "# 각 클래스에서 가장 많은 선택을 받은 이미지 10장씩을 모아놓은 10,000장의 이미지가 포함된 topimages 데이터셋 사용\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "content_data_url = '/content/sample_data'\n",
    "data_root_orig = tf.keras.utils.get_file('imagenetV2', 'https://s3-us-west-2.amazonaws.com/imagenetv2public/imagenetv2-top-images.tar.gz', cache_dir=content_data_url, extract=True)\n",
    "data_root = pathlib.Path(content_data_url + \"/datasets/imagenetv2-topimages\")\n",
    "print(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "affbf8be",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.6.5-py3-none-any.whl (1.5 MB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2021.11.2-cp37-cp37m-win_amd64.whl (272 kB)\n",
      "Requirement already satisfied: click in c:\\users\\seunghwan\\.conda\\envs\\nnew\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\seunghwan\\.conda\\envs\\nnew\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\seunghwan\\.conda\\envs\\nnew\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\seunghwan\\.conda\\envs\\nnew\\lib\\site-packages (from click->nltk) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\seunghwan\\.conda\\envs\\nnew\\lib\\site-packages (from importlib-metadata->click->nltk) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\seunghwan\\.conda\\envs\\nnew\\lib\\site-packages (from importlib-metadata->click->nltk) (3.7.4.3)\n",
      "Installing collected packages: tqdm, regex, nltk\n",
      "Successfully installed nltk-3.6.5 regex-2021.11.2 tqdm-4.62.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1367592a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n",
      "['background', 'tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead', 'electric ray', 'stingray', 'cock', 'hen']\n",
      "['buckeye', 'coral fungus', 'agaric', 'gyromitra', 'stinkhorn', 'earthstar', 'hen-of-the-woods', 'bolete', 'ear', 'toilet tissue']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\seunghwan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "# ImageNet 라벨 텍스트 불러오기\n",
    "\n",
    "label_file = tf.keras.utils.get_file('label', 'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
    "label_text = None\n",
    "with open(label_file, 'r') as f:\n",
    "    label_text = f.read().split('\\n')[:-1]\n",
    "print(len(label_text))\n",
    "print(label_text[:10])\n",
    "print(label_text[-10:])\n",
    "\n",
    "# 폴더 이름이 wordnet의 단어로 수정되었기 때문에, nltk 패키지에서 wordnet을 다운받기\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# wordnet과 인터넷에 올라온 label 텍스트는 조금씩 다르기 때문에 차이를 없애기 위해서 아래의 전처리 작업을 진행합니다.\n",
    "label_text = [c.lower().replace('-','').replace('_','').replace(' ','') for c in label_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6205c378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_count: 0\n"
     ]
    }
   ],
   "source": [
    "# 이미지 확인 \n",
    "\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "all_image_paths = list(data_root.glob('*/*'))\n",
    "all_image_paths = [str(path) for path in all_image_paths]\n",
    "# 이미지를 랜덤하게 섞습니다.\n",
    "random.shuffle(all_image_paths)\n",
    "\n",
    "image_count = len(all_image_paths)\n",
    "print('image_count:', image_count)\n",
    "\n",
    "# plt.figure(figsize=(12,12))\n",
    "# for c in range(9):\n",
    "#     image_path = random.choice(all_image_paths)\n",
    "#     plt.subplot(3,3,c+1)\n",
    "#     plt.imshow(plt.imread(image_path))\n",
    "#     # idx = int(image_path.split('/')[-2]) + 1\n",
    "#     # plt.title(str(idx) + ', ' + label_text[idx])\n",
    "#     word = wordnet.synset_from_pos_and_offset('n',int(image_path.split('/')[-2][1:]))\n",
    "#     word = word.name().split('.')[0].replace('-','').replace('_','').replace(' ','')\n",
    "#     plt.title(str(label_text.index(word)) + ', ' + word)\n",
    "#     plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ba95c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('/content/sample_data/datasets/imagenetv2-topimages')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f7ee72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnew(3.8)",
   "language": "python",
   "name": "nnew"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
